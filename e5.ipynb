{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3aa5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy.signal import butter, filtfilt\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1, freq = librosa.load(r\"C:\\Users\\taian\\UFSC\\LVA\\teste1.waptt.wav\", sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=audio1, rate=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac36b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loudness\n",
    "\n",
    "potencia = np.square(audio1)\n",
    "loudness = np.mean(potencia)\n",
    "\n",
    "def resultLoudness(loudness):\n",
    "\n",
    "    if loudness > 0.05:\n",
    "        return \"Som barulhento.\"\n",
    "    else:\n",
    "        return \"Som baixo.\"\n",
    "\n",
    "print(resultLoudness(loudness))\n",
    "\n",
    "\"\"\"como a audição humana está mais associada com a energia do som\n",
    "do que com a amplitude, fiz o quadrado da amplitude e tirei a média,\n",
    "a escolha do 0.05 foi com base nos valores comuns para sons 'neutros', \n",
    "já que sons comuns variam entre 0.001 e 0.2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sharpness\n",
    "\n",
    "mediaEspectro = np.mean(np.abs(librosa.stft(audio1)), axis=1)\n",
    "taxaAmostral = librosa.fft_frequencies(sr=freq)\n",
    "\n",
    "mediaFreq = np.sum(taxaAmostral * mediaEspectro) / np.sum(mediaEspectro)\n",
    "\n",
    "print(f\"Frequência média: {mediaFreq:.2f} Hz\")\n",
    "\n",
    "def resultSharpness(mediaFreq):\n",
    "\n",
    "    if mediaFreq < 250:\n",
    "        return \"Som grave.\"\n",
    "    elif 250 < mediaFreq < 2500:\n",
    "        return \"Som médio.\"\n",
    "    else:\n",
    "        return \"Som agudo.\"\n",
    "\n",
    "print(resultSharpness(mediaFreq))\n",
    "\n",
    "\"\"\"primeiro fiz a transformada para ter as frequencias de cada ponto e\n",
    "depois tirei a média para verificar em qual frequencia o audio está concentrado\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd651cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flutuação lenta\n",
    "varLenta = librosa.feature.rms(y=audio1, frame_length=2048)[0]\n",
    "fluctStrength = np.std(varLenta)\n",
    "\n",
    "#flutuação rápida\n",
    "roughness = np.mean(np.abs(np.diff(audio1)))\n",
    "\n",
    "print(f\"Fluctuation Strength: {fluctStrength:.6f}\")\n",
    "print(f\"Roughness: {roughness:.6f}\")\n",
    "\n",
    "def resultStrenght(fluctStrength):\n",
    "\n",
    "    if fluctStrength > 0.01:\n",
    "        return \"Possui flutuações lentas.\"\n",
    "    else:\n",
    "        return \"O som é estável.\"\n",
    "\n",
    "print(resultStrenght(fluctStrength))\n",
    "\n",
    "def resultRoughness(roughness):\n",
    "    if roughness > 0.02:\n",
    "        return \"Possui flutuação rápida.\"\n",
    "    else:\n",
    "        return \"O som é suave.\"\n",
    "\n",
    "print(resultRoughness(roughness))\n",
    "\n",
    "\"\"\"'separei' o audio em janelas e depois tirei o desvio padrão (como a janela é\n",
    "grande, percebe variações lentas de volume), quanto maior o desvio padrão, mais varia,\n",
    "ou seja, indica que existe flutuação, por fim, verifiquei a diferença entre as janelas\n",
    "(para verificar se existe variações rápidas)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tonality\n",
    "\n",
    "mediaEspec = np.mean(np.abs(librosa.stft(audio1)), axis=1)\n",
    "frequencias = librosa.fft_frequencies(sr=freq)\n",
    "freqDominante = frequencias[np.argmax(mediaEspec)]\n",
    "\n",
    "print(f\"Frequência dominante: {freqDominante:.2f} Hz\")\n",
    "\n",
    "def resultTonality(freqDominante):\n",
    "\n",
    "    if freqDominante < 300:\n",
    "        return \"Tonalidade grave.\" #(ronco, batida)\n",
    "    elif freqDominante < 1500:\n",
    "        return \"Tonalidade média.\" #(voz humana)\n",
    "    elif freqDominante < 5000:\n",
    "        return \"Tonalidade sibilante.\" #('s' ou 'sh')\n",
    "    else:\n",
    "        return \"Tonalidade assobiante ou muito aguda.\" #(como apitos)\n",
    "\n",
    "print(resultTonality(freqDominante))\n",
    "\n",
    "\"\"\"a analise é bem parecida com a do sharpness, porém nesse caso\n",
    "usei a frequencia que mais concentrada 'dominante' para estimar o tonality,\n",
    "o que não deixa de ser uma classificação subjetiva\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dea4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch\n",
    "\n",
    "pitch, magnitudes = librosa.piptrack(y=audio1, sr=freq)\n",
    "\n",
    "freqPitch = []\n",
    "for i in range(pitch.shape[1]):\n",
    "    idx = np.argmax(magnitudes[:, i])\n",
    "    frequencia = pitch[idx, i]\n",
    "    if frequencia > 0:\n",
    "        freqPitch.append(frequencia)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(freqPitch)\n",
    "plt.title(\"Variação do Pitch ao longo do tempo\")\n",
    "plt.ylabel(\"Frequência (Hz)\")\n",
    "plt.xlabel(\"Quadros\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"primeiro usei o piptrack para obter a frequencia fundamental de cada\n",
    "janela e a intensidade de cada pitch, peguei as frequencias com maior\n",
    "intensidade para estimar o pitch (já que tem maior 'probabilidade' de ser o pitch),\n",
    "e por fim plotei no gráfico\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92772266",
   "metadata": {},
   "outputs": [],
   "source": [
    "classLoudness = resultLoudness(loudness)\n",
    "classSharpness = resultSharpness(mediaFreq)\n",
    "classFluctuation = resultStrenght(fluctStrength)\n",
    "classRoughness = resultRoughness(roughness)\n",
    "classTonality = resultTonality(freqDominante)\n",
    "\n",
    "resultados = {\n",
    "    \"Loudness\": loudness,\n",
    "    \"Classificação Loudness\": classLoudness,\n",
    "    \"Sharpness\": mediaFreq,\n",
    "    \"Classificação Sharpness\": classSharpness,\n",
    "    \"Fluctuation Strength\": fluctStrength,\n",
    "    \"Classificação Flutuação\": classFluctuation,\n",
    "    \"Roughness\": roughness,\n",
    "    \"Classificação Roughness\": classRoughness,\n",
    "    \"Tonality\": freqDominante,\n",
    "    \"Classificação Tonality\": classTonality,\n",
    "    \"Pitch\": sum(freqPitch)/len(freqPitch) if freqPitch else 0\n",
    "}\n",
    "\n",
    "dfResults = pd.DataFrame([resultados])\n",
    "\n",
    "dfResults.to_csv(\"relatorioAudio.csv\", index=False)\n",
    "\n",
    "FileLink(r'relatorio_audio.csv')\n",
    "print(\"Relatório salvo em relatorioAudio.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
